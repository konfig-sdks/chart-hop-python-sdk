# coding: utf-8

"""
    ChartHop API

    REST API for ChartHop

    The version of the OpenAPI document: V1.0.0
    Contact: support@charthop.com
    Created by: https://www.charthop.com
"""

from datetime import date, datetime  # noqa: F401
import decimal  # noqa: F401
import functools  # noqa: F401
import io  # noqa: F401
import re  # noqa: F401
import typing  # noqa: F401
import typing_extensions  # noqa: F401
import uuid  # noqa: F401

import frozendict  # noqa: F401

from chart_hop_python_sdk import schemas  # noqa: F401


class AiModelConfig(
    schemas.DictSchema
):
    """
    This class is auto generated by Konfig (https://konfigthis.com)
    """


    class MetaOapg:
        required = {
            "promptBefore",
            "modelId",
            "promptAfter",
            "maxTokens",
            "temperature",
            "maxStringLength",
            "topP",
        }
        
        class properties:
            modelId = schemas.StrSchema
            promptBefore = schemas.StrSchema
            promptAfter = schemas.StrSchema
            maxTokens = schemas.Int32Schema
            temperature = schemas.Float64Schema
            topP = schemas.Int32Schema
            maxStringLength = schemas.Int32Schema
            stopSequences = schemas.StrSchema
            __annotations__ = {
                "modelId": modelId,
                "promptBefore": promptBefore,
                "promptAfter": promptAfter,
                "maxTokens": maxTokens,
                "temperature": temperature,
                "topP": topP,
                "maxStringLength": maxStringLength,
                "stopSequences": stopSequences,
            }
    
    promptBefore: MetaOapg.properties.promptBefore
    modelId: MetaOapg.properties.modelId
    promptAfter: MetaOapg.properties.promptAfter
    maxTokens: MetaOapg.properties.maxTokens
    temperature: MetaOapg.properties.temperature
    maxStringLength: MetaOapg.properties.maxStringLength
    topP: MetaOapg.properties.topP
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["modelId"]) -> MetaOapg.properties.modelId: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["promptBefore"]) -> MetaOapg.properties.promptBefore: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["promptAfter"]) -> MetaOapg.properties.promptAfter: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["maxTokens"]) -> MetaOapg.properties.maxTokens: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["temperature"]) -> MetaOapg.properties.temperature: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["topP"]) -> MetaOapg.properties.topP: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["maxStringLength"]) -> MetaOapg.properties.maxStringLength: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["stopSequences"]) -> MetaOapg.properties.stopSequences: ...
    
    @typing.overload
    def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
    
    def __getitem__(self, name: typing.Union[typing_extensions.Literal["modelId", "promptBefore", "promptAfter", "maxTokens", "temperature", "topP", "maxStringLength", "stopSequences", ], str]):
        # dict_instance[name] accessor
        return super().__getitem__(name)
    
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["modelId"]) -> MetaOapg.properties.modelId: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["promptBefore"]) -> MetaOapg.properties.promptBefore: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["promptAfter"]) -> MetaOapg.properties.promptAfter: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["maxTokens"]) -> MetaOapg.properties.maxTokens: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["temperature"]) -> MetaOapg.properties.temperature: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["topP"]) -> MetaOapg.properties.topP: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["maxStringLength"]) -> MetaOapg.properties.maxStringLength: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["stopSequences"]) -> typing.Union[MetaOapg.properties.stopSequences, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
    
    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["modelId", "promptBefore", "promptAfter", "maxTokens", "temperature", "topP", "maxStringLength", "stopSequences", ], str]):
        return super().get_item_oapg(name)
    

    def __new__(
        cls,
        *args: typing.Union[dict, frozendict.frozendict, ],
        promptBefore: typing.Union[MetaOapg.properties.promptBefore, str, ],
        modelId: typing.Union[MetaOapg.properties.modelId, str, ],
        promptAfter: typing.Union[MetaOapg.properties.promptAfter, str, ],
        maxTokens: typing.Union[MetaOapg.properties.maxTokens, decimal.Decimal, int, ],
        temperature: typing.Union[MetaOapg.properties.temperature, decimal.Decimal, int, float, ],
        maxStringLength: typing.Union[MetaOapg.properties.maxStringLength, decimal.Decimal, int, ],
        topP: typing.Union[MetaOapg.properties.topP, decimal.Decimal, int, ],
        stopSequences: typing.Union[MetaOapg.properties.stopSequences, str, schemas.Unset] = schemas.unset,
        _configuration: typing.Optional[schemas.Configuration] = None,
        **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
    ) -> 'AiModelConfig':
        return super().__new__(
            cls,
            *args,
            promptBefore=promptBefore,
            modelId=modelId,
            promptAfter=promptAfter,
            maxTokens=maxTokens,
            temperature=temperature,
            maxStringLength=maxStringLength,
            topP=topP,
            stopSequences=stopSequences,
            _configuration=_configuration,
            **kwargs,
        )
